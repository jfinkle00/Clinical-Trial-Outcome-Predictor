{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\uddec Clinical Trial Outcome Predictor\n",
    "\n",
    "**Author:** Jason Finkle  \n",
    "**Project:** Healthcare/Biotech ML Classification  \n",
    "\n",
    "This project predicts whether a clinical trial will successfully complete or terminate early using data from [ClinicalTrials.gov](https://clinicaltrials.gov). By analyzing trial characteristics such as phase, sponsor type, enrollment size, and study design, we build machine learning models to identify factors associated with trial success.\n",
    "\n",
    "**Business Value:** Clinical trials cost an average of $20-40 million. Early prediction of trial failure could help pharmaceutical companies and research institutions allocate resources more effectively and identify at-risk trials for intervention.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nimport time\nimport warnings\nfrom datetime import datetime\nfrom collections import Counter\nwarnings.filterwarnings('ignore')\n\n# Scikit-learn\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n                             classification_report, confusion_matrix, roc_curve, auc,\n                             precision_recall_curve, average_precision_score)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\n\n# Model Interpretability\nimport shap\n\n# Survival Analysis\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.statistics import logrank_test\n\n# Set random seed\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\n# Create figures directory\nimport os\nos.makedirs('figures', exist_ok=True)\nos.makedirs('data', exist_ok=True)\n\n# Define color palette\nCOLORS = {\n    'primary': '#2E86AB',\n    'secondary': '#A23B72',\n    'accent': '#F18F01',\n    'success': '#28A745',\n    'danger': '#DC3545',\n    'dark': '#343A40',\n    'purple': '#6F42C1',\n    'teal': '#20C997'\n}\n\n# Plot style\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['font.size'] = 11\nplt.rcParams['axes.titlesize'] = 14\nplt.rcParams['axes.labelsize'] = 12\n\nprint(\"\u2705 Libraries loaded successfully\")\nprint(\"   - SHAP for model interpretability\")\nprint(\"   - Lifelines for survival analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection from ClinicalTrials.gov API\n",
    "\n",
    "We'll use the ClinicalTrials.gov API v2 to fetch clinical trials with definitive outcomes:\n",
    "- **COMPLETED** \u2192 Success (Target = 1)\n",
    "- **TERMINATED** \u2192 Failure (Target = 0)\n",
    "\n",
    "We focus on interventional trials (not observational) with drug, biological, or device interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_clinical_trials(status, max_studies=5000, page_size=100):\n",
    "    \"\"\"\n",
    "    Fetch clinical trials from ClinicalTrials.gov API v2\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    status : str\n",
    "        Trial status (COMPLETED or TERMINATED)\n",
    "    max_studies : int\n",
    "        Maximum number of studies to fetch\n",
    "    page_size : int\n",
    "        Number of studies per API request (max 100)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : List of study dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "    all_studies = []\n",
    "    page_token = None\n",
    "    \n",
    "    # Fields to request\n",
    "    fields = [\n",
    "        \"NCTId\",\n",
    "        \"BriefTitle\",\n",
    "        \"OverallStatus\",\n",
    "        \"Phase\",\n",
    "        \"StudyType\",\n",
    "        \"EnrollmentCount\",\n",
    "        \"EnrollmentType\",\n",
    "        \"StartDate\",\n",
    "        \"PrimaryCompletionDate\",\n",
    "        \"CompletionDate\",\n",
    "        \"LeadSponsorName\",\n",
    "        \"LeadSponsorClass\",\n",
    "        \"CollaboratorName\",\n",
    "        \"InterventionType\",\n",
    "        \"InterventionName\",\n",
    "        \"Condition\",\n",
    "        \"DesignAllocation\",\n",
    "        \"DesignInterventionModel\",\n",
    "        \"DesignPrimaryPurpose\",\n",
    "        \"DesignMasking\",\n",
    "        \"ArmGroupType\",\n",
    "        \"LocationCountry\",\n",
    "        \"MinimumAge\",\n",
    "        \"MaximumAge\",\n",
    "        \"Sex\",\n",
    "        \"StdAge\",\n",
    "        \"IsFDARegulatedDrug\",\n",
    "        \"IsFDARegulatedDevice\",\n",
    "        \"WhyStopped\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\ud83d\udce5 Fetching {status} trials...\")\n",
    "    \n",
    "    while len(all_studies) < max_studies:\n",
    "        params = {\n",
    "            \"format\": \"json\",\n",
    "            \"pageSize\": min(page_size, max_studies - len(all_studies)),\n",
    "            \"filter.overallStatus\": status,\n",
    "            \"query.term\": \"AREA[StudyType]INTERVENTIONAL\",\n",
    "            \"fields\": \"|\".join(fields),\n",
    "            \"countTotal\": \"true\"\n",
    "        }\n",
    "        \n",
    "        if page_token:\n",
    "            params[\"pageToken\"] = page_token\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            studies = data.get(\"studies\", [])\n",
    "            if not studies:\n",
    "                break\n",
    "                \n",
    "            all_studies.extend(studies)\n",
    "            \n",
    "            # Get next page token\n",
    "            page_token = data.get(\"nextPageToken\")\n",
    "            if not page_token:\n",
    "                break\n",
    "            \n",
    "            # Progress update\n",
    "            if len(all_studies) % 500 == 0:\n",
    "                print(f\"   Retrieved {len(all_studies):,} studies...\")\n",
    "            \n",
    "            # Rate limiting (be respectful to the API)\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"   \u26a0\ufe0f API error: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"   \u2705 Retrieved {len(all_studies):,} {status} trials\")\n",
    "    return all_studies\n",
    "\n",
    "# Check if data already exists (to avoid re-fetching)\n",
    "DATA_FILE = \"data/clinical_trials_raw.csv\"\n",
    "\n",
    "if os.path.exists(DATA_FILE):\n",
    "    print(f\"\ud83d\udcc2 Loading cached data from {DATA_FILE}\")\n",
    "    df_raw = pd.read_csv(DATA_FILE)\n",
    "    print(f\"   Loaded {len(df_raw):,} trials\")\n",
    "else:\n",
    "    print(\"\ud83c\udf10 Fetching data from ClinicalTrials.gov API...\")\n",
    "    print(\"   (This may take 5-10 minutes)\\n\")\n",
    "    \n",
    "    # Fetch completed and terminated trials\n",
    "    completed_trials = fetch_clinical_trials(\"COMPLETED\", max_studies=4000)\n",
    "    terminated_trials = fetch_clinical_trials(\"TERMINATED\", max_studies=2000)\n",
    "    \n",
    "    # Combine\n",
    "    all_trials = completed_trials + terminated_trials\n",
    "    print(f\"\\n\ud83d\udcca Total trials fetched: {len(all_trials):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trial_features(study):\n",
    "    \"\"\"\n",
    "    Extract relevant features from a study record\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    study : dict\n",
    "        Raw study data from API\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Extracted features\n",
    "    \"\"\"\n",
    "    \n",
    "    protocol = study.get(\"protocolSection\", {})\n",
    "    \n",
    "    # Identification\n",
    "    id_module = protocol.get(\"identificationModule\", {})\n",
    "    nct_id = id_module.get(\"nctId\", \"\")\n",
    "    brief_title = id_module.get(\"briefTitle\", \"\")\n",
    "    \n",
    "    # Status\n",
    "    status_module = protocol.get(\"statusModule\", {})\n",
    "    overall_status = status_module.get(\"overallStatus\", \"\")\n",
    "    why_stopped = status_module.get(\"whyStopped\", \"\")\n",
    "    \n",
    "    # Dates\n",
    "    start_date = status_module.get(\"startDateStruct\", {}).get(\"date\", \"\")\n",
    "    completion_date = status_module.get(\"completionDateStruct\", {}).get(\"date\", \"\")\n",
    "    primary_completion = status_module.get(\"primaryCompletionDateStruct\", {}).get(\"date\", \"\")\n",
    "    \n",
    "    # Sponsor\n",
    "    sponsor_module = protocol.get(\"sponsorCollaboratorsModule\", {})\n",
    "    lead_sponsor = sponsor_module.get(\"leadSponsor\", {})\n",
    "    sponsor_name = lead_sponsor.get(\"name\", \"\")\n",
    "    sponsor_class = lead_sponsor.get(\"class\", \"\")  # INDUSTRY, NIH, FED, OTHER, etc.\n",
    "    \n",
    "    # Collaborators count\n",
    "    collaborators = sponsor_module.get(\"collaborators\", [])\n",
    "    num_collaborators = len(collaborators) if collaborators else 0\n",
    "    \n",
    "    # Design\n",
    "    design_module = protocol.get(\"designModule\", {})\n",
    "    study_type = design_module.get(\"studyType\", \"\")\n",
    "    phases = design_module.get(\"phases\", [])\n",
    "    phase = phases[0] if phases else \"NA\"\n",
    "    \n",
    "    design_info = design_module.get(\"designInfo\", {})\n",
    "    allocation = design_info.get(\"allocation\", \"\")\n",
    "    intervention_model = design_info.get(\"interventionModel\", \"\")\n",
    "    primary_purpose = design_info.get(\"primaryPurpose\", \"\")\n",
    "    masking = design_info.get(\"maskingInfo\", {}).get(\"masking\", \"\")\n",
    "    \n",
    "    # Enrollment\n",
    "    enrollment_info = design_module.get(\"enrollmentInfo\", {})\n",
    "    enrollment_count = enrollment_info.get(\"count\", 0)\n",
    "    enrollment_type = enrollment_info.get(\"type\", \"\")\n",
    "    \n",
    "    # Arms\n",
    "    arms_module = protocol.get(\"armsInterventionsModule\", {})\n",
    "    arms = arms_module.get(\"armGroups\", [])\n",
    "    num_arms = len(arms) if arms else 0\n",
    "    \n",
    "    # Interventions\n",
    "    interventions = arms_module.get(\"interventions\", [])\n",
    "    num_interventions = len(interventions) if interventions else 0\n",
    "    intervention_types = [i.get(\"type\", \"\") for i in interventions] if interventions else []\n",
    "    primary_intervention_type = intervention_types[0] if intervention_types else \"\"\n",
    "    \n",
    "    # Conditions\n",
    "    conditions_module = protocol.get(\"conditionsModule\", {})\n",
    "    conditions = conditions_module.get(\"conditions\", [])\n",
    "    num_conditions = len(conditions) if conditions else 0\n",
    "    primary_condition = conditions[0] if conditions else \"\"\n",
    "    \n",
    "    # Eligibility\n",
    "    eligibility_module = protocol.get(\"eligibilityModule\", {})\n",
    "    sex = eligibility_module.get(\"sex\", \"\")\n",
    "    min_age = eligibility_module.get(\"minimumAge\", \"\")\n",
    "    max_age = eligibility_module.get(\"maximumAge\", \"\")\n",
    "    std_ages = eligibility_module.get(\"stdAges\", [])\n",
    "    \n",
    "    # Locations\n",
    "    contacts_module = protocol.get(\"contactsLocationsModule\", {})\n",
    "    locations = contacts_module.get(\"locations\", [])\n",
    "    num_locations = len(locations) if locations else 0\n",
    "    countries = list(set([loc.get(\"country\", \"\") for loc in locations])) if locations else []\n",
    "    num_countries = len(countries)\n",
    "    is_us = \"United States\" in countries if countries else False\n",
    "    \n",
    "    # Oversight\n",
    "    oversight_module = protocol.get(\"oversightModule\", {})\n",
    "    is_fda_drug = oversight_module.get(\"isFDARegulatedDrug\", False)\n",
    "    is_fda_device = oversight_module.get(\"isFDARegulatedDevice\", False)\n",
    "    \n",
    "    return {\n",
    "        'nct_id': nct_id,\n",
    "        'brief_title': brief_title,\n",
    "        'overall_status': overall_status,\n",
    "        'why_stopped': why_stopped,\n",
    "        'start_date': start_date,\n",
    "        'completion_date': completion_date,\n",
    "        'primary_completion_date': primary_completion,\n",
    "        'sponsor_name': sponsor_name,\n",
    "        'sponsor_class': sponsor_class,\n",
    "        'num_collaborators': num_collaborators,\n",
    "        'study_type': study_type,\n",
    "        'phase': phase,\n",
    "        'allocation': allocation,\n",
    "        'intervention_model': intervention_model,\n",
    "        'primary_purpose': primary_purpose,\n",
    "        'masking': masking,\n",
    "        'enrollment_count': enrollment_count,\n",
    "        'enrollment_type': enrollment_type,\n",
    "        'num_arms': num_arms,\n",
    "        'num_interventions': num_interventions,\n",
    "        'primary_intervention_type': primary_intervention_type,\n",
    "        'num_conditions': num_conditions,\n",
    "        'primary_condition': primary_condition,\n",
    "        'sex': sex,\n",
    "        'min_age': min_age,\n",
    "        'max_age': max_age,\n",
    "        'includes_children': 'CHILD' in std_ages if std_ages else False,\n",
    "        'includes_adults': 'ADULT' in std_ages if std_ages else False,\n",
    "        'includes_older_adults': 'OLDER_ADULT' in std_ages if std_ages else False,\n",
    "        'num_locations': num_locations,\n",
    "        'num_countries': num_countries,\n",
    "        'is_us_trial': is_us,\n",
    "        'is_fda_drug': is_fda_drug,\n",
    "        'is_fda_device': is_fda_device\n",
    "    }\n",
    "\n",
    "# Process trials if not already cached\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    print(\"\\n\ud83d\udd04 Processing trial data...\")\n",
    "    \n",
    "    processed_trials = []\n",
    "    for i, study in enumerate(all_trials):\n",
    "        try:\n",
    "            features = extract_trial_features(study)\n",
    "            processed_trials.append(features)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"   Processed {i + 1:,} trials...\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_raw = pd.DataFrame(processed_trials)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df_raw.to_csv(DATA_FILE, index=False)\n",
    "    print(f\"\\n\u2705 Saved {len(df_raw):,} trials to {DATA_FILE}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Dataset shape: {df_raw.shape}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"\ud83d\udcca DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total trials: {len(df_raw):,}\")\n",
    "print(f\"Features: {len(df_raw.columns)}\")\n",
    "print(f\"\\nStatus distribution:\")\n",
    "print(df_raw['overall_status'].value_counts())\n",
    "print(f\"\\nCompletion rate: {(df_raw['overall_status'] == 'COMPLETED').mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"\\n\ud83d\udd0d MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "missing = df_raw.isnull().sum()\n",
    "missing_pct = (missing / len(df_raw) * 100).round(1)\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
    "print(missing_df[missing_df['Missing'] > 0].sort_values('Percent', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean dataset for modeling\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Create target variable: 1 = Completed (success), 0 = Terminated (failure)\n",
    "df['outcome'] = (df['overall_status'] == 'COMPLETED').astype(int)\n",
    "\n",
    "# Parse dates and calculate duration\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Parse date string to datetime\"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return None\n",
    "    try:\n",
    "        # Try different formats\n",
    "        for fmt in ['%Y-%m-%d', '%Y-%m', '%B %Y', '%B %d, %Y']:\n",
    "            try:\n",
    "                return datetime.strptime(str(date_str), fmt)\n",
    "            except:\n",
    "                continue\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['start_dt'] = df['start_date'].apply(parse_date)\n",
    "df['completion_dt'] = df['completion_date'].apply(parse_date)\n",
    "\n",
    "# Calculate planned duration in months\n",
    "df['duration_months'] = df.apply(\n",
    "    lambda row: (row['completion_dt'] - row['start_dt']).days / 30.44 \n",
    "    if pd.notna(row['start_dt']) and pd.notna(row['completion_dt']) else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Clean phase\n",
    "phase_mapping = {\n",
    "    'EARLY_PHASE1': 'Phase 1',\n",
    "    'PHASE1': 'Phase 1',\n",
    "    'PHASE2': 'Phase 2', \n",
    "    'PHASE3': 'Phase 3',\n",
    "    'PHASE4': 'Phase 4',\n",
    "    'NA': 'Not Applicable'\n",
    "}\n",
    "df['phase_clean'] = df['phase'].map(phase_mapping).fillna('Other')\n",
    "\n",
    "# Clean sponsor class\n",
    "sponsor_mapping = {\n",
    "    'INDUSTRY': 'Industry',\n",
    "    'NIH': 'NIH/Government',\n",
    "    'FED': 'NIH/Government',\n",
    "    'OTHER_GOV': 'NIH/Government',\n",
    "    'NETWORK': 'Academic/Network',\n",
    "    'OTHER': 'Other/Academic'\n",
    "}\n",
    "df['sponsor_type'] = df['sponsor_class'].map(sponsor_mapping).fillna('Other/Academic')\n",
    "\n",
    "# Clean intervention type\n",
    "intervention_mapping = {\n",
    "    'DRUG': 'Drug',\n",
    "    'BIOLOGICAL': 'Biological',\n",
    "    'DEVICE': 'Device',\n",
    "    'PROCEDURE': 'Procedure',\n",
    "    'BEHAVIORAL': 'Behavioral',\n",
    "    'DIETARY_SUPPLEMENT': 'Other',\n",
    "    'RADIATION': 'Other',\n",
    "    'GENETIC': 'Other',\n",
    "    'COMBINATION_PRODUCT': 'Drug',\n",
    "    'DIAGNOSTIC_TEST': 'Other',\n",
    "    'OTHER': 'Other'\n",
    "}\n",
    "df['intervention_type_clean'] = df['primary_intervention_type'].map(intervention_mapping).fillna('Other')\n",
    "\n",
    "# Clean masking\n",
    "masking_mapping = {\n",
    "    'NONE': 'Open Label',\n",
    "    'SINGLE': 'Single Blind',\n",
    "    'DOUBLE': 'Double Blind',\n",
    "    'TRIPLE': 'Triple+ Blind',\n",
    "    'QUADRUPLE': 'Triple+ Blind'\n",
    "}\n",
    "df['masking_clean'] = df['masking'].map(masking_mapping).fillna('Open Label')\n",
    "\n",
    "# Clean allocation\n",
    "df['is_randomized'] = df['allocation'].str.contains('RANDOMIZED', case=False, na=False).astype(int)\n",
    "\n",
    "# Create size categories\n",
    "df['enrollment_clean'] = pd.to_numeric(df['enrollment_count'], errors='coerce').fillna(0)\n",
    "df['size_category'] = pd.cut(\n",
    "    df['enrollment_clean'],\n",
    "    bins=[0, 50, 100, 250, 500, 1000, float('inf')],\n",
    "    labels=['Very Small (<50)', 'Small (50-100)', 'Medium (100-250)', \n",
    "            'Large (250-500)', 'Very Large (500-1000)', 'Mega (>1000)']\n",
    ")\n",
    "\n",
    "print(\"\u2705 Data cleaning complete\")\n",
    "print(f\"\\nCleaned dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Outcome Distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "outcome_counts = df['outcome'].value_counts()\n",
    "labels = ['Terminated', 'Completed']\n",
    "colors_outcome = [COLORS['danger'], COLORS['success']]\n",
    "\n",
    "bars = ax.bar(labels, [outcome_counts[0], outcome_counts[1]], \n",
    "              color=colors_outcome, width=0.6, edgecolor='white', linewidth=2)\n",
    "\n",
    "for bar, val in zip(bars, [outcome_counts[0], outcome_counts[1]]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "            f'{val:,}\\n({val/len(df)*100:.1f}%)', ha='center', va='bottom', \n",
    "            fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_title('Clinical Trial Outcomes', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_ylabel('Number of Trials', fontsize=12)\n",
    "ax.set_ylim(0, max(outcome_counts) * 1.2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/01_outcome_distribution.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/01_outcome_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Completion Rate by Phase\n",
    "phase_completion = df.groupby('phase_clean')['outcome'].agg(['mean', 'count']).reset_index()\n",
    "phase_completion.columns = ['Phase', 'Completion Rate', 'Count']\n",
    "phase_completion = phase_completion[phase_completion['Count'] >= 50]  # Filter low counts\n",
    "phase_completion = phase_completion.sort_values('Completion Rate')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors_phase = [COLORS['danger'] if r < 0.7 else COLORS['success'] \n",
    "                for r in phase_completion['Completion Rate']]\n",
    "\n",
    "bars = ax.barh(phase_completion['Phase'], phase_completion['Completion Rate'],\n",
    "               color=colors_phase, edgecolor='white', height=0.6)\n",
    "\n",
    "for bar, (_, row) in zip(bars, phase_completion.iterrows()):\n",
    "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{row['Completion Rate']:.1%} (n={row['Count']:,.0f})\",\n",
    "            va='center', fontsize=10)\n",
    "\n",
    "ax.axvline(x=0.7, color='gray', linestyle='--', alpha=0.7, label='70% threshold')\n",
    "ax.set_xlabel('Completion Rate', fontsize=12)\n",
    "ax.set_title('Trial Completion Rate by Phase', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlim(0, 1.15)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/02_completion_by_phase.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/02_completion_by_phase.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Completion Rate by Sponsor Type\n",
    "sponsor_completion = df.groupby('sponsor_type')['outcome'].agg(['mean', 'count']).reset_index()\n",
    "sponsor_completion.columns = ['Sponsor', 'Completion Rate', 'Count']\n",
    "sponsor_completion = sponsor_completion.sort_values('Completion Rate')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors_sponsor = [COLORS['danger'] if r < 0.7 else COLORS['success'] \n",
    "                  for r in sponsor_completion['Completion Rate']]\n",
    "\n",
    "bars = ax.barh(sponsor_completion['Sponsor'], sponsor_completion['Completion Rate'],\n",
    "               color=colors_sponsor, edgecolor='white', height=0.6)\n",
    "\n",
    "for bar, (_, row) in zip(bars, sponsor_completion.iterrows()):\n",
    "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{row['Completion Rate']:.1%} (n={row['Count']:,.0f})\",\n",
    "            va='center', fontsize=10)\n",
    "\n",
    "ax.axvline(x=0.7, color='gray', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('Completion Rate', fontsize=12)\n",
    "ax.set_title('Trial Completion Rate by Sponsor Type', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlim(0, 1.15)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/03_completion_by_sponsor.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/03_completion_by_sponsor.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Completion Rate by Intervention Type\n",
    "intervention_completion = df.groupby('intervention_type_clean')['outcome'].agg(['mean', 'count']).reset_index()\n",
    "intervention_completion.columns = ['Intervention', 'Completion Rate', 'Count']\n",
    "intervention_completion = intervention_completion[intervention_completion['Count'] >= 30]\n",
    "intervention_completion = intervention_completion.sort_values('Completion Rate')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors_int = plt.cm.RdYlGn(intervention_completion['Completion Rate'])\n",
    "\n",
    "bars = ax.barh(intervention_completion['Intervention'], intervention_completion['Completion Rate'],\n",
    "               color=colors_int, edgecolor='white', height=0.6)\n",
    "\n",
    "for bar, (_, row) in zip(bars, intervention_completion.iterrows()):\n",
    "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{row['Completion Rate']:.1%} (n={row['Count']:,.0f})\",\n",
    "            va='center', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Completion Rate', fontsize=12)\n",
    "ax.set_title('Trial Completion Rate by Intervention Type', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlim(0, 1.15)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/04_completion_by_intervention.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/04_completion_by_intervention.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: Enrollment Size Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Distribution by outcome\n",
    "ax1 = axes[0]\n",
    "for outcome, color, label in [(1, COLORS['success'], 'Completed'), (0, COLORS['danger'], 'Terminated')]:\n",
    "    data = df[df['outcome'] == outcome]['enrollment_clean']\n",
    "    data = data[(data > 0) & (data < 2000)]  # Filter outliers\n",
    "    ax1.hist(data, bins=50, alpha=0.6, color=color, label=label, edgecolor='white')\n",
    "\n",
    "ax1.set_xlabel('Enrollment Size', fontsize=12)\n",
    "ax1.set_ylabel('Number of Trials', fontsize=12)\n",
    "ax1.set_title('Enrollment Distribution by Outcome', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Right: Completion rate by size category\n",
    "ax2 = axes[1]\n",
    "size_completion = df.groupby('size_category')['outcome'].agg(['mean', 'count']).reset_index()\n",
    "size_completion.columns = ['Size', 'Rate', 'Count']\n",
    "size_completion = size_completion.dropna()\n",
    "\n",
    "colors_size = plt.cm.RdYlGn(size_completion['Rate'])\n",
    "bars = ax2.bar(range(len(size_completion)), size_completion['Rate'], \n",
    "               color=colors_size, edgecolor='white')\n",
    "ax2.set_xticks(range(len(size_completion)))\n",
    "ax2.set_xticklabels(size_completion['Size'], rotation=45, ha='right')\n",
    "ax2.set_ylabel('Completion Rate', fontsize=12)\n",
    "ax2.set_title('Completion Rate by Trial Size', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/05_enrollment_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/05_enrollment_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6: Masking and Randomization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: By masking\n",
    "ax1 = axes[0]\n",
    "masking_completion = df.groupby('masking_clean')['outcome'].agg(['mean', 'count']).reset_index()\n",
    "masking_completion.columns = ['Masking', 'Rate', 'Count']\n",
    "masking_completion = masking_completion[masking_completion['Count'] >= 50]\n",
    "masking_completion = masking_completion.sort_values('Rate')\n",
    "\n",
    "colors_mask = plt.cm.RdYlGn(masking_completion['Rate'])\n",
    "bars = ax1.barh(masking_completion['Masking'], masking_completion['Rate'],\n",
    "                color=colors_mask, edgecolor='white', height=0.5)\n",
    "\n",
    "for bar, (_, row) in zip(bars, masking_completion.iterrows()):\n",
    "    ax1.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "             f\"{row['Rate']:.1%}\", va='center', fontsize=10)\n",
    "\n",
    "ax1.set_xlabel('Completion Rate', fontsize=12)\n",
    "ax1.set_title('By Masking Type', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlim(0, 1.1)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# Right: Randomized vs Non-randomized\n",
    "ax2 = axes[1]\n",
    "rand_completion = df.groupby('is_randomized')['outcome'].mean()\n",
    "labels = ['Non-Randomized', 'Randomized']\n",
    "values = [rand_completion.get(0, 0), rand_completion.get(1, 0)]\n",
    "colors_rand = [COLORS['accent'], COLORS['primary']]\n",
    "\n",
    "bars = ax2.bar(labels, values, color=colors_rand, width=0.5, edgecolor='white')\n",
    "for bar, val in zip(bars, values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f'{val:.1%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax2.set_ylabel('Completion Rate', fontsize=12)\n",
    "ax2.set_title('By Randomization', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.suptitle('Study Design Impact on Completion', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/06_design_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/06_design_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix\n",
    "df_model = df.copy()\n",
    "\n",
    "# Select and encode features\n",
    "feature_columns = []\n",
    "\n",
    "# Numeric features\n",
    "numeric_features = [\n",
    "    'enrollment_clean',\n",
    "    'num_arms',\n",
    "    'num_interventions', \n",
    "    'num_conditions',\n",
    "    'num_locations',\n",
    "    'num_countries',\n",
    "    'num_collaborators'\n",
    "]\n",
    "\n",
    "# Fill missing values with median\n",
    "for col in numeric_features:\n",
    "    df_model[col] = pd.to_numeric(df_model[col], errors='coerce').fillna(0)\n",
    "\n",
    "feature_columns.extend(numeric_features)\n",
    "\n",
    "# Binary features\n",
    "binary_features = [\n",
    "    'is_randomized',\n",
    "    'is_us_trial',\n",
    "    'is_fda_drug',\n",
    "    'is_fda_device',\n",
    "    'includes_children',\n",
    "    'includes_adults',\n",
    "    'includes_older_adults'\n",
    "]\n",
    "\n",
    "for col in binary_features:\n",
    "    df_model[col] = df_model[col].astype(int)\n",
    "\n",
    "feature_columns.extend(binary_features)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_features = [\n",
    "    'phase_clean',\n",
    "    'sponsor_type',\n",
    "    'intervention_type_clean',\n",
    "    'masking_clean'\n",
    "]\n",
    "\n",
    "for col in categorical_features:\n",
    "    dummies = pd.get_dummies(df_model[col], prefix=col, drop_first=True)\n",
    "    df_model = pd.concat([df_model, dummies], axis=1)\n",
    "    feature_columns.extend(dummies.columns.tolist())\n",
    "\n",
    "# Log transform enrollment (helps with skewness)\n",
    "df_model['log_enrollment'] = np.log1p(df_model['enrollment_clean'])\n",
    "feature_columns.append('log_enrollment')\n",
    "\n",
    "# Create feature matrix\n",
    "X = df_model[feature_columns].copy()\n",
    "y = df_model['outcome'].copy()\n",
    "\n",
    "# Remove any rows with NaN\n",
    "valid_idx = X.notna().all(axis=1) & y.notna()\n",
    "X = X[valid_idx]\n",
    "y = y[valid_idx]\n",
    "\n",
    "print(\"\ud83d\udcca FEATURE MATRIX\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Samples: {len(X):,}\")\n",
    "print(f\"Features: {len(feature_columns)}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\ud83d\udcca TRAIN/TEST SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Test samples: {len(X_test):,}\")\n",
    "print(f\"Training completion rate: {y_train.mean()*100:.1f}%\")\n",
    "print(f\"Test completion rate: {y_test.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models with class_weight='balanced' to handle class imbalance\n# This automatically adjusts weights inversely proportional to class frequencies\nmodels = {\n    'Logistic Regression': LogisticRegression(\n        random_state=RANDOM_STATE, \n        max_iter=1000,\n        class_weight='balanced'  # Handle imbalanced classes\n    ),\n    'Random Forest': RandomForestClassifier(\n        n_estimators=100, \n        random_state=RANDOM_STATE, \n        n_jobs=-1,\n        class_weight='balanced'  # Handle imbalanced classes\n    ),\n    'Gradient Boosting': GradientBoostingClassifier(\n        n_estimators=100, \n        random_state=RANDOM_STATE\n        # Note: GB doesn't support class_weight, but we use stratified CV\n    ),\n    'SVM': SVC(\n        probability=True, \n        random_state=RANDOM_STATE,\n        class_weight='balanced'  # Handle imbalanced classes\n    )\n}\n\n# Cross-validation with stratification preserves class distribution\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n\n# Store results\nresults = {}\ncv_scores = {}\n\nprint(\"\ud83e\udd16 TRAINING MODELS WITH 5-FOLD CROSS-VALIDATION\")\nprint(\"=\" * 60)\nprint(\"\ud83d\udcca Class imbalance handling: class_weight='balanced'\")\nprint(f\"   Minority class (Terminated): {(y_train == 0).sum():,} samples\")\nprint(f\"   Majority class (Completed): {(y_train == 1).sum():,} samples\")\nprint(f\"   Imbalance ratio: {(y_train == 1).sum() / (y_train == 0).sum():.2f}:1\")\n\nfor name, model in models.items():\n    print(f\"\\n\ud83d\udcc8 Training {name}...\")\n    \n    # Use scaled data for SVM and Logistic, original for tree-based\n    if name in ['Logistic Regression', 'SVM']:\n        X_tr, X_te = X_train_scaled, X_test_scaled\n    else:\n        X_tr, X_te = X_train.values, X_test.values\n    \n    # Cross-validation\n    scores = cross_val_score(model, X_tr, y_train, cv=cv, scoring='roc_auc')\n    cv_scores[name] = scores\n    print(f\"   CV AUC: {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n    \n    # Fit on full training set\n    model.fit(X_tr, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_te)\n    y_prob = model.predict_proba(X_te)[:, 1]\n    \n    # Calculate metrics\n    fpr, tpr, _ = roc_curve(y_test, y_prob)\n    roc_auc = auc(fpr, tpr)\n    \n    results[name] = {\n        'model': model,\n        'y_pred': y_pred,\n        'y_prob': y_prob,\n        'fpr': fpr,\n        'tpr': tpr,\n        'accuracy': accuracy_score(y_test, y_pred),\n        'precision': precision_score(y_test, y_pred),\n        'recall': recall_score(y_test, y_pred),\n        'f1': f1_score(y_test, y_pred),\n        'auc': roc_auc,\n        'cv_mean': scores.mean(),\n        'cv_std': scores.std()\n    }\n    \n    print(f\"   Test AUC: {roc_auc:.4f}\")\n    print(f\"   Test Accuracy: {results[name]['accuracy']:.4f}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2705 All models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metrics summary\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'CV AUC': [f\"{results[m]['cv_mean']:.4f} \u00b1 {results[m]['cv_std']:.4f}\" for m in results],\n",
    "    'Test AUC': [results[m]['auc'] for m in results],\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1 Score': [results[m]['f1'] for m in results]\n",
    "}).round(4)\n",
    "\n",
    "metrics_df = metrics_df.sort_values('Test AUC', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\ud83d\udcca MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Save\n",
    "metrics_df.to_csv('model_metrics_summary.csv', index=False)\n",
    "print(\"\\n\u2705 Saved: model_metrics_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7: ROC Curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors_models = [COLORS['primary'], COLORS['secondary'], COLORS['accent'], COLORS['purple']]\n",
    "\n",
    "for (name, res), color in zip(results.items(), colors_models):\n",
    "    ax.plot(res['fpr'], res['tpr'], color=color, lw=2,\n",
    "            label=f\"{name} (AUC = {res['auc']:.3f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=1.5, alpha=0.7, label='Random Classifier')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves: Model Comparison', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/07_roc_curves.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/07_roc_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8: Metrics Comparison\n",
    "metrics_to_plot = ['Test AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "model_names = list(results.keys())\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    if metric == 'Test AUC':\n",
    "        values = [results[m]['auc'] for m in model_names]\n",
    "    elif metric == 'Accuracy':\n",
    "        values = [results[m]['accuracy'] for m in model_names]\n",
    "    elif metric == 'Precision':\n",
    "        values = [results[m]['precision'] for m in model_names]\n",
    "    elif metric == 'Recall':\n",
    "        values = [results[m]['recall'] for m in model_names]\n",
    "    else:\n",
    "        values = [results[m]['f1'] for m in model_names]\n",
    "    \n",
    "    y_pos = np.arange(len(model_names))\n",
    "    bars = ax.barh(y_pos, values, color=colors_models, edgecolor='white', height=0.6)\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.text(val + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "                f'{val:.3f}', va='center', fontsize=10)\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(model_names)\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Hide empty subplot\n",
    "axes[5].set_visible(False)\n",
    "\n",
    "plt.suptitle('Model Performance Comparison', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/08_metrics_comparison.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/08_metrics_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9: Feature Importance (Random Forest)\n",
    "rf_model = results['Random Forest']['model']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=True).tail(15)  # Top 15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors_imp = plt.cm.Blues(np.linspace(0.4, 0.9, len(feature_importance)))\n",
    "bars = ax.barh(feature_importance['Feature'], feature_importance['Importance'],\n",
    "               color=colors_imp, edgecolor='white', height=0.6)\n",
    "\n",
    "for bar, val in zip(bars, feature_importance['Importance']):\n",
    "    ax.text(val + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "            f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Importance Score', fontsize=12)\n",
    "ax.set_title('Top 15 Feature Importance (Random Forest)', fontsize=14, fontweight='bold', pad=15)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/09_feature_importance.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/09_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Interpretability with SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) values provide a unified measure of feature importance that shows how each feature contributes to individual predictions. This is critical for healthcare applications where model interpretability is required for regulatory and clinical adoption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Analysis for Random Forest (best interpretable model)\nprint(\"\ud83d\udd0d Computing SHAP values for model interpretability...\")\nprint(\"   (This may take a minute)\\n\")\n\n# Get the Random Forest model\nrf_model = results['Random Forest']['model']\n\n# Create SHAP explainer\nexplainer = shap.TreeExplainer(rf_model)\n\n# Calculate SHAP values for test set\nshap_values = explainer.shap_values(X_test.values)\n\n# For binary classification, shap_values is a list [class_0, class_1]\n# We use class 1 (Completed) for interpretation\nif isinstance(shap_values, list):\n    shap_values_class1 = shap_values[1]\nelse:\n    shap_values_class1 = shap_values\n\nprint(\"\u2705 SHAP values computed!\")\nprint(f\"   Shape: {shap_values_class1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 12: SHAP Summary Plot\nfig, ax = plt.subplots(figsize=(12, 10))\n\nshap.summary_plot(\n    shap_values_class1, \n    X_test, \n    feature_names=feature_columns,\n    plot_type=\"dot\",\n    show=False,\n    max_display=20\n)\n\nplt.title('SHAP Feature Impact on Trial Completion Prediction', fontsize=14, fontweight='bold', pad=15)\nplt.tight_layout()\nplt.savefig('figures/12_shap_summary.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.show()\nprint(\"\u2705 Saved: figures/12_shap_summary.png\")\n\nprint(\"\\n\ud83d\udcca SHAP INTERPRETATION:\")\nprint(\"   \u2022 Red points = high feature values\")\nprint(\"   \u2022 Blue points = low feature values\")\nprint(\"   \u2022 Position on x-axis = impact on completion probability\")\nprint(\"   \u2022 Right of center = increases completion likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 13: SHAP Bar Plot (Mean Absolute Impact)\nfig, ax = plt.subplots(figsize=(10, 8))\n\nshap.summary_plot(\n    shap_values_class1, \n    X_test, \n    feature_names=feature_columns,\n    plot_type=\"bar\",\n    show=False,\n    max_display=15\n)\n\nplt.title('Mean Absolute SHAP Value (Feature Importance)', fontsize=14, fontweight='bold', pad=15)\nplt.tight_layout()\nplt.savefig('figures/13_shap_importance.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.show()\nprint(\"\u2705 Saved: figures/13_shap_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Survival Analysis\n",
    "\n",
    "Survival analysis examines the time until trial completion or termination. Kaplan-Meier curves visualize the probability of a trial still being 'at risk' (not yet completed/terminated) over time. This is a standard biostatistical technique used in clinical research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for survival analysis\n# Duration = time from start to completion/termination (in months)\n# Event = 1 for both completed and terminated (both are observed events)\n\ndf_survival = df[['duration_months', 'outcome', 'phase_clean', 'sponsor_type']].copy()\ndf_survival = df_survival.dropna(subset=['duration_months'])\ndf_survival = df_survival[df_survival['duration_months'] > 0]\ndf_survival = df_survival[df_survival['duration_months'] < 120]  # Filter outliers (>10 years)\n\n# For survival analysis, we treat termination as \"failure\" and completion as \"success\"\n# Both are observed events, but we can compare survival curves by outcome\ndf_survival['event'] = 1  # All trials have an observed endpoint\n\nprint(\"\ud83d\udcca SURVIVAL ANALYSIS DATA\")\nprint(\"=\" * 60)\nprint(f\"Trials with valid duration: {len(df_survival):,}\")\nprint(f\"Median duration: {df_survival['duration_months'].median():.1f} months\")\nprint(f\"Mean duration: {df_survival['duration_months'].mean():.1f} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 14: Kaplan-Meier Curves by Trial Phase\nfig, ax = plt.subplots(figsize=(12, 8))\n\nkmf = KaplanMeierFitter()\nphases_to_plot = ['Phase 1', 'Phase 2', 'Phase 3', 'Phase 4']\ncolors_km = [COLORS['primary'], COLORS['secondary'], COLORS['accent'], COLORS['success']]\n\nfor phase, color in zip(phases_to_plot, colors_km):\n    mask = df_survival['phase_clean'] == phase\n    if mask.sum() > 50:  # Only plot phases with sufficient data\n        kmf.fit(\n            df_survival.loc[mask, 'duration_months'],\n            df_survival.loc[mask, 'event'],\n            label=f\"{phase} (n={mask.sum():,})\"\n        )\n        kmf.plot_survival_function(ax=ax, color=color, linewidth=2)\n\nax.set_xlabel('Time (Months)', fontsize=12)\nax.set_ylabel('Probability of Trial Still Active', fontsize=12)\nax.set_title('Kaplan-Meier Survival Curves by Trial Phase', fontsize=14, fontweight='bold', pad=15)\nax.legend(loc='lower left', fontsize=10)\nax.set_xlim(0, 72)  # 6 years\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('figures/14_km_by_phase.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.show()\nprint(\"\u2705 Saved: figures/14_km_by_phase.png\")\n\nprint(\"\\n\ud83d\udcc8 INTERPRETATION:\")\nprint(\"   \u2022 Curves show probability of trial not yet reaching endpoint\")\nprint(\"   \u2022 Steeper drops = faster trial completion/termination\")\nprint(\"   \u2022 Phase differences reflect varying regulatory complexity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 15: Kaplan-Meier Curves by Sponsor Type\nfig, ax = plt.subplots(figsize=(12, 8))\n\nkmf = KaplanMeierFitter()\nsponsors_to_plot = df_survival['sponsor_type'].value_counts().head(4).index.tolist()\ncolors_sp = [COLORS['primary'], COLORS['secondary'], COLORS['accent'], COLORS['purple']]\n\nfor sponsor, color in zip(sponsors_to_plot, colors_sp):\n    mask = df_survival['sponsor_type'] == sponsor\n    if mask.sum() > 50:\n        kmf.fit(\n            df_survival.loc[mask, 'duration_months'],\n            df_survival.loc[mask, 'event'],\n            label=f\"{sponsor} (n={mask.sum():,})\"\n        )\n        kmf.plot_survival_function(ax=ax, color=color, linewidth=2)\n\nax.set_xlabel('Time (Months)', fontsize=12)\nax.set_ylabel('Probability of Trial Still Active', fontsize=12)\nax.set_title('Kaplan-Meier Survival Curves by Sponsor Type', fontsize=14, fontweight='bold', pad=15)\nax.legend(loc='lower left', fontsize=10)\nax.set_xlim(0, 72)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\nplt.tight_layout()\nplt.savefig('figures/15_km_by_sponsor.png', dpi=300, bbox_inches='tight', facecolor='white')\nplt.show()\nprint(\"\u2705 Saved: figures/15_km_by_sponsor.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-rank test: Statistical comparison between groups\nprint(\"\\n\ud83d\udcca LOG-RANK TESTS (Statistical Significance)\")\nprint(\"=\" * 60)\n\n# Compare Industry vs Academic\nindustry = df_survival[df_survival['sponsor_type'] == 'Industry']\nacademic = df_survival[df_survival['sponsor_type'] == 'Other/Academic']\n\nif len(industry) > 50 and len(academic) > 50:\n    result = logrank_test(\n        industry['duration_months'], academic['duration_months'],\n        industry['event'], academic['event']\n    )\n    print(f\"\\nIndustry vs Academic:\")\n    print(f\"   Test statistic: {result.test_statistic:.2f}\")\n    print(f\"   p-value: {result.p_value:.4f}\")\n    print(f\"   Significant: {'Yes' if result.p_value < 0.05 else 'No'} (\u03b1=0.05)\")\n\n# Compare Phase 2 vs Phase 3\nphase2 = df_survival[df_survival['phase_clean'] == 'Phase 2']\nphase3 = df_survival[df_survival['phase_clean'] == 'Phase 3']\n\nif len(phase2) > 50 and len(phase3) > 50:\n    result = logrank_test(\n        phase2['duration_months'], phase3['duration_months'],\n        phase2['event'], phase3['event']\n    )\n    print(f\"\\nPhase 2 vs Phase 3:\")\n    print(f\"   Test statistic: {result.test_statistic:.2f}\")\n    print(f\"   p-value: {result.p_value:.4f}\")\n    print(f\"   Significant: {'Yes' if result.p_value < 0.05 else 'No'} (\u03b1=0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 10: Confusion Matrix (Best Model)\n",
    "best_model_name = metrics_df.iloc[0]['Model']\n",
    "best_results = results[best_model_name]\n",
    "\n",
    "cm = confusion_matrix(y_test, best_results['y_pred'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Terminated', 'Completed'],\n",
    "            yticklabels=['Terminated', 'Completed'],\n",
    "            annot_kws={'size': 16}, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_title(f'Confusion Matrix: {best_model_name}\\n(AUC: {best_results[\"auc\"]:.3f})',\n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/10_confusion_matrix.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/10_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 11: Prediction Probability Distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "prob_completed = best_results['y_prob'][y_test == 1]\n",
    "prob_terminated = best_results['y_prob'][y_test == 0]\n",
    "\n",
    "ax.hist(prob_terminated, bins=30, alpha=0.6, label='Actually Terminated',\n",
    "        color=COLORS['danger'], edgecolor='white')\n",
    "ax.hist(prob_completed, bins=30, alpha=0.6, label='Actually Completed',\n",
    "        color=COLORS['success'], edgecolor='white')\n",
    "\n",
    "ax.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "\n",
    "ax.set_xlabel('Predicted Probability of Completion', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title(f'Prediction Probability Distribution: {best_model_name}',\n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.legend()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/11_probability_distribution.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(\"\u2705 Saved: figures/11_probability_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\nprint(\"                    \ud83d\udcca FINAL PROJECT SUMMARY\")\nprint(\"=\" * 70)\n\nprint(f\"\\n\ud83d\udcc8 Dataset: {len(df):,} clinical trials from ClinicalTrials.gov\")\nprint(f\"   - Completed: {(df['outcome'] == 1).sum():,} ({df['outcome'].mean()*100:.1f}%)\")\nprint(f\"   - Terminated: {(df['outcome'] == 0).sum():,} ({(1-df['outcome'].mean())*100:.1f}%)\")\n\nprint(f\"\\n\ud83c\udfc6 Best Model: {best_model_name}\")\nprint(f\"   Test AUC: {best_results['auc']:.4f}\")\nprint(f\"   Accuracy: {best_results['accuracy']:.4f}\")\nprint(f\"   Precision: {best_results['precision']:.4f}\")\nprint(f\"   Recall: {best_results['recall']:.4f}\")\n\nprint(\"\\n\ud83d\udd11 KEY FINDINGS:\")\nprint(\"\\n   1. PHASE MATTERS:\")\nprint(\"      - Phase 4 trials have highest completion rates\")\nprint(\"      - Phase 2/3 trials are riskiest (efficacy uncertainty)\")\n\nprint(\"\\n   2. SPONSOR IMPACT:\")\nprint(\"      - Industry-sponsored trials complete more often\")\nprint(\"      - Academic trials face more resource constraints\")\n\nprint(\"\\n   3. DESIGN FACTORS:\")\nprint(\"      - Larger enrollment = higher termination risk\")\nprint(\"      - Randomized trials have better completion rates\")\nprint(\"      - Multi-site trials face coordination challenges\")\n\nprint(\"\\n   4. INTERVENTION TYPE:\")\nprint(\"      - Drug trials have moderate completion rates\")\nprint(\"      - Behavioral interventions often complete\")\nprint(\"      - Device trials face regulatory hurdles\")\n\nprint(\"\\n\ud83d\udcc1 Outputs generated:\")\nprint(\"   - 15 figures in figures/ directory\")\nprint(\"   - model_metrics_summary.csv\")\nprint(\"   - data/clinical_trials_raw.csv (cached API data)\")\n\nprint(\"\\n\ud83d\udd2c ADVANCED ANALYTICS:\")\nprint(\"   - SHAP values for model interpretability\")\nprint(\"   - Kaplan-Meier survival curves by phase/sponsor\")\nprint(\"   - Log-rank statistical tests\")\n\nprint(\"\\n\ud83d\udca1 BUSINESS APPLICATIONS:\")\nprint(\"   - Risk assessment for trial portfolio management\")\nprint(\"   - Resource allocation for at-risk trials\")\nprint(\"   - Go/no-go decision support for sponsors\")\nprint(\"   - Trial design optimization\")\nprint(\"   - Regulatory submission support (interpretable models)\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"      Project by Jason Finkle | github.com/jfinkle00\")\nprint(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}